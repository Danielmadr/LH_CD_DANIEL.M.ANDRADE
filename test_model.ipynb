{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c4db52",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (Python 3.12.10)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/danie/OneDrive/Desktop/LH_CD_DANIEL.M.ANDRADE/.venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# train_models.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "from scripts.preprocess import preprocess_movies_df\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import optuna\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "vectorizer = None\n",
    "svd = None\n",
    "\n",
    "\n",
    "def objective(trial, X, y):\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 800, 2000),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.15, log=True),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-3, 10.0, log=True),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-3, 3.0, log=True),\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"objective\": \"reg:squarederror\",\n",
    "        \"n_jobs\": -1,\n",
    "        \"random_state\": 42,\n",
    "    }\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    rmses = []\n",
    "\n",
    "    for train_idx, valid_idx in kf.split(X):\n",
    "        X_tr, X_va = X.iloc[train_idx].astype(np.float32), X.iloc[valid_idx].astype(np.float32)\n",
    "        y_tr, y_va = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "\n",
    "        model = XGBRegressor(**params)\n",
    "        model.fit(\n",
    "            X_tr, \n",
    "            y_tr, eval_set=[(X_va, y_va)], \n",
    "            verbose=False, \n",
    "            )\n",
    "        pred = model.predict(X_va)\n",
    "        rmses.append(np.sqrt(mean_squared_error(y_va, pred)))\n",
    "\n",
    "        trial.report(np.mean(rmses), step=len(rmses))\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "    return float(np.mean(rmses))\n",
    "\n",
    "\n",
    "def run_optuna_two_phase(X, y):\n",
    "    print(\"\\nüîé Fase 1: Busca ampla (80 trials)\")\n",
    "    study1 = optuna.create_study(direction=\"minimize\", pruner=optuna.pruners.MedianPruner())\n",
    "    study1.optimize(lambda t: objective(t, X, y), n_trials=80)\n",
    "\n",
    "    best_params = study1.best_params\n",
    "    print(\"\\nüèÜ Melhores par√¢metros Fase 1:\")\n",
    "    for k, v in best_params.items():\n",
    "        print(f\"   {k}: {v}\")\n",
    "    print(f\"‚úÖ Melhor RMSE (CV 5-fold): {study1.best_value:.4f}\")\n",
    "\n",
    "    def objective_refine(trial, X, y):\n",
    "        params = {\n",
    "            \"n_estimators\": trial.suggest_int(\n",
    "                \"n_estimators\", max(500, best_params[\"n_estimators\"] - 200), best_params[\"n_estimators\"] + 200\n",
    "            ),\n",
    "            \"learning_rate\": trial.suggest_float(\n",
    "                \"learning_rate\", max(0.005, best_params[\"learning_rate\"] * 0.7),\n",
    "                best_params[\"learning_rate\"] * 1.3, log=True\n",
    "            ),\n",
    "            \"max_depth\": trial.suggest_int(\n",
    "                \"max_depth\", max(2, best_params[\"max_depth\"] - 2), min(12, best_params[\"max_depth\"] + 2)\n",
    "            ),\n",
    "            \"min_child_weight\": trial.suggest_int(\n",
    "                \"min_child_weight\", max(1, best_params[\"min_child_weight\"] - 2), best_params[\"min_child_weight\"] + 2\n",
    "            ),\n",
    "            \"subsample\": trial.suggest_float(\n",
    "                \"subsample\", max(0.5, best_params[\"subsample\"] - 0.1), min(1.0, best_params[\"subsample\"] + 0.1)\n",
    "            ),\n",
    "            \"colsample_bytree\": trial.suggest_float(\n",
    "                \"colsample_bytree\", max(0.5, best_params[\"colsample_bytree\"] - 0.1), min(1.0, best_params[\"colsample_bytree\"] + 0.1)\n",
    "            ),\n",
    "            \"reg_lambda\": trial.suggest_float(\n",
    "                \"reg_lambda\", max(1e-3, best_params[\"reg_lambda\"] * 0.5), best_params[\"reg_lambda\"] * 1.5, log=True\n",
    "            ),\n",
    "            \"reg_alpha\": trial.suggest_float(\n",
    "                \"reg_alpha\", max(1e-3, best_params[\"reg_alpha\"] * 0.5), best_params[\"reg_alpha\"] * 1.5, log=True\n",
    "            ),\n",
    "            \"tree_method\": \"hist\",\n",
    "            \"objective\": \"reg:squarederror\",\n",
    "            \"n_jobs\": -1,\n",
    "            \"random_state\": 42,\n",
    "        }\n",
    "\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        rmses = []\n",
    "\n",
    "        for train_idx, valid_idx in kf.split(X):\n",
    "            X_tr, X_va = X.iloc[train_idx].astype(np.float32), X.iloc[valid_idx].astype(np.float32)\n",
    "            y_tr, y_va = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "\n",
    "            model = XGBRegressor(**params)\n",
    "            model.fit(\n",
    "                X_tr, y_tr, \n",
    "                eval_set=[(X_va, y_va)], \n",
    "                verbose=False\n",
    "                )\n",
    "            pred = model.predict(X_va)\n",
    "            rmses.append(np.sqrt(mean_squared_error(y_va, pred)))\n",
    "\n",
    "            trial.report(np.mean(rmses), step=len(rmses))\n",
    "            if trial.should_prune():\n",
    "                raise optuna.TrialPruned()\n",
    "\n",
    "        return float(np.mean(rmses))\n",
    "\n",
    "    print(\"\\nüîé Fase 2: Refinamento (100 trials)\")\n",
    "    study2 = optuna.create_study(direction=\"minimize\", pruner=optuna.pruners.MedianPruner())\n",
    "    study2.optimize(lambda t: objective_refine(t, X, y), n_trials=100)\n",
    "\n",
    "    best_params_final = study2.best_params\n",
    "    print(\"\\nüèÜ Melhores par√¢metros finais (Fase 2):\")\n",
    "    for k, v in best_params_final.items():\n",
    "        print(f\"   {k}: {v}\")\n",
    "    print(f\"‚úÖ Melhor RMSE (CV 5-fold): {study2.best_value:.4f}\")\n",
    "\n",
    "    best_model = XGBRegressor(**best_params_final)\n",
    "    best_model.fit(X.astype(np.float32), y)\n",
    "    return best_model\n",
    "\n",
    "def basic_clean(df):\n",
    "    global vectorizer, svd\n",
    "    COLS_TO_DROP = [\"id\", \"Series_Title\"]\n",
    "\n",
    "    df = df.copy()\n",
    "    df.columns = [c.strip() for c in df.columns]\n",
    "\n",
    "    for col in COLS_TO_DROP:\n",
    "        if col in df.columns:\n",
    "            df.drop(columns=col, inplace=True)\n",
    "\n",
    "    df = df.dropna()\n",
    "    df = preprocess_movies_df(df)\n",
    "\n",
    "    if 'Released_Year' in df.columns:\n",
    "        current_year = datetime.now().year\n",
    "        df['Released_Year'] = df['Released_Year'].fillna(df['Released_Year'].median()).infer_objects(copy=False)\n",
    "        df['Movie_Age'] = current_year - df['Released_Year']\n",
    "        df['Is_Recent'] = (df['Movie_Age'] <= 5).astype(int)\n",
    "        df['Is_Classic'] = (df['Movie_Age'] >= 30).astype(int)\n",
    "\n",
    "    if 'No_of_Votes' in df.columns:\n",
    "        df['Log_Votes'] = np.log1p(df['No_of_Votes'].fillna(0))\n",
    "        df['High_Votes'] = (df['No_of_Votes'] > df['No_of_Votes'].quantile(0.75)).astype(int)\n",
    "\n",
    "    if 'Gross' in df.columns:\n",
    "        filled_gross = pd.to_numeric(df['Gross'], errors=\"coerce\").fillna(0)\n",
    "        df['Log_Gross'] = np.log1p(filled_gross)\n",
    "        df['Has_Gross'] = df['Gross'].notna().astype(int)\n",
    "        df['Gross'] = filled_gross\n",
    "\n",
    "    if 'Meta_score' in df.columns:\n",
    "        df['Has_Meta_Score'] = df['Meta_score'].notna().astype(int)\n",
    "        filled_meta_score = pd.to_numeric(df['Meta_score'], errors=\"coerce\")\n",
    "        meta_median = filled_meta_score.median()\n",
    "        df['Meta_score'] = filled_meta_score.fillna(meta_median)\n",
    "\n",
    "    if 'Runtime' in df.columns:\n",
    "        filled_runtime = pd.to_numeric(df['Runtime'], errors=\"coerce\")\n",
    "        runtime_median = filled_runtime.median()\n",
    "        df['Runtime_filled'] = filled_runtime.fillna(runtime_median)\n",
    "        df['Is_Long_Movie'] = (df['Runtime_filled'] > 120).astype(int)\n",
    "        df['Is_Short_Movie'] = (df['Runtime_filled'] < 90).astype(int)\n",
    "        df['Runtime'] = filled_runtime.fillna(runtime_median)\n",
    "\n",
    "    if \"Genre\" in df.columns:\n",
    "        df['Genre'] = df['Genre'].fillna('Unknown')\n",
    "        df[\"Main_Genre\"] = df[\"Genre\"].astype(str).str.split(\",\").str[0]\n",
    "        genre_dummies = pd.get_dummies(df[\"Genre\"].astype(str), prefix=\"Genre\")\n",
    "        df = pd.concat([df, genre_dummies], axis=1)\n",
    "\n",
    "    for col in [\"Director\", \"Star1\", \"Star2\", \"Star3\", \"Star4\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].fillna('Unknown')\n",
    "            freq = df[col].value_counts()\n",
    "            df[f\"{col}_Freq\"] = df[col].map(freq).fillna(0)\n",
    "\n",
    "    if \"Released_Year\" in df.columns:\n",
    "        df[\"Decade\"] = (df[\"Released_Year\"] // 10) * 10\n",
    "\n",
    "    for col in [\"Certificate\", \"Overview\", \"Genre\", \"Director\", \"Star1\", \"Star2\", \"Star3\", \"Star4\"]:\n",
    "        if col in df.columns:\n",
    "            df.drop(columns=col, inplace=True)\n",
    "\n",
    "    for col in df.columns:\n",
    "        if col != 'IMDB_Rating' and df[col].dtype == 'object':\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "    if 'IMDB_Rating' in df.columns:\n",
    "        df = df.dropna(subset=['IMDB_Rating'])\n",
    "\n",
    "    df = df.fillna(0).infer_objects(copy=False)\n",
    "    return df\n",
    "\n",
    "\n",
    "def split_X_y(df: pd.DataFrame):\n",
    "    X = df.drop(columns=[\"IMDB_Rating\"])\n",
    "    y = df[\"IMDB_Rating\"]\n",
    "    return X, y\n",
    "\n",
    "def train_models(csv_path: str):\n",
    "    df_raw = pd.read_csv(csv_path, sep=\",\", quotechar='\"', encoding=\"utf-8\", low_memory=False)\n",
    "    df_raw = df_raw.drop(df_raw.columns[0], axis=1)\n",
    "    df_clean = basic_clean(df_raw)\n",
    "\n",
    "    if df_clean.shape[0] == 0:\n",
    "        print(\"‚ùå Erro: Nenhum dado restou ap√≥s o processamento!\")\n",
    "        return\n",
    "\n",
    "    X, y = split_X_y(df_clean)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    print(f\"üî¢ N√∫mero de amostras: {X.shape[0]}\")\n",
    "    print(f\"üéõÔ∏è N√∫mero de features: {X.shape[1]}\")\n",
    "\n",
    "    # RandomForest\n",
    "    rf = RandomForestRegressor(n_estimators=300, random_state=42, n_jobs=-1)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "    # XGBoost baseline\n",
    "    xgb = XGBRegressor(\n",
    "        n_estimators=600, learning_rate=0.09, max_depth=6,\n",
    "        subsample=0.94, colsample_bytree=1, random_state=42,\n",
    "        reg_lambda=1.0, reg_alpha=0.09, verbosity=0,\n",
    "        tree_method='hist', n_jobs=-1, objective='reg:squarederror',\n",
    "    )\n",
    "    xgb.fit(X_train.astype(np.float32), y_train)\n",
    "    y_pred_xgb = xgb.predict(X_test.astype(np.float32))\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üìä M√âTRICAS HOLD-OUT (20% Test)\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    print(\"\\nüå≤ RANDOM FOREST:\")\n",
    "    print(f\"   RMSE = {np.sqrt(mean_squared_error(y_test, y_pred_rf)):.4f}\")\n",
    "    print(f\"   MAE  = {mean_absolute_error(y_test, y_pred_rf):.4f}\")\n",
    "    print(f\"   R¬≤   = {r2_score(y_test, y_pred_rf):.4f}\")\n",
    "\n",
    "    print(\"\\n‚ö° XGBOOST:\")\n",
    "    print(f\"   RMSE = {np.sqrt(mean_squared_error(y_test, y_pred_xgb)):.4f}\")\n",
    "    print(f\"   MAE  = {mean_absolute_error(y_test, y_pred_xgb):.4f}\")\n",
    "    print(f\"   R¬≤   = {r2_score(y_test, y_pred_xgb):.4f}\")\n",
    "\n",
    "    #Optuna tuned\n",
    "    # xgb_best = run_optuna_two_phase(X, y)\n",
    "    # y_pred_xgb_best = xgb_best.predict(X_test.astype(np.float32))\n",
    "\n",
    "    # print(\"\\n‚ö° XGBOOST (Optuna Tuned):\")\n",
    "    # print(f\"   RMSE = {np.sqrt(mean_squared_error(y_test, y_pred_xgb_best)):.4f}\")\n",
    "    # print(f\"   MAE  = {mean_absolute_error(y_test, y_pred_xgb_best):.4f}\")\n",
    "    # print(f\"   R¬≤   = {r2_score(y_test, y_pred_xgb_best):.4f}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üéØ TOP 5 FEATURES MAIS IMPORTANTES\")\n",
    "    print(\"=\"*60)\n",
    "    rf_importance = pd.DataFrame({'feature': X.columns, 'importance': rf.feature_importances_}) \\\n",
    "        .sort_values('importance', ascending=False).head(5)\n",
    "    xgb_importance = pd.DataFrame({'feature': X.columns, 'importance': xgb.feature_importances_}) \\\n",
    "        .sort_values('importance', ascending=False).head(5)\n",
    "\n",
    "    print(\"\\nüå≤ RANDOM FOREST:\")\n",
    "    for i, (_, row) in enumerate(rf_importance.iterrows(), 1):\n",
    "        print(f\"   {i}. {row['feature']}: {row['importance']:.4f}\")\n",
    "\n",
    "    print(\"\\n‚ö° XGBOOST:\")\n",
    "    for i, (_, row) in enumerate(xgb_importance.iterrows(), 1):\n",
    "        print(f\"   {i}. {row['feature']}: {row['importance']:.4f}\")\n",
    "\n",
    "    # Teste em filmes\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üé¨ TESTE: The Shawshank Redemption\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    shawshank = {\n",
    "        'Series_Title': 'The Shawshank Redemption',\n",
    "        'Released_Year': 1994,\n",
    "        'Certificate': 'A',\n",
    "        'Runtime': '142 min',\n",
    "        'Genre': 'Drama',\n",
    "        'Overview': 'Two imprisoned men bond over a number of years.',\n",
    "        'Meta_score': 80.0,\n",
    "        'Director': 'Frank Darabont',\n",
    "        'Star1': 'Tim Robbins',\n",
    "        'Star2': 'Morgan Freeman',\n",
    "        'Star3': 'Bob Gunton',\n",
    "        'Star4': 'William Sadler',\n",
    "        'No_of_Votes': 2343110,\n",
    "        'Gross': '28341469'\n",
    "    }\n",
    "    godfather = {\n",
    "        \"Series_Title\": \"The Godfather\",\n",
    "        \"Released_Year\": 1972,\n",
    "        \"Certificate\": \"A\",\n",
    "        \"Runtime\": \"175 min\",\n",
    "        \"Genre\": \"Crime, Drama\",\n",
    "        \"Overview\": \"An organized crime dynasty's aging patriarch transfers control of his clandestine empire to his reluctant son.\",\n",
    "        \"Meta_score\": 100.0,\n",
    "        \"Director\": \"Francis Ford Coppola\",\n",
    "        \"Star1\": \"Marlon Brando\",\n",
    "        \"Star2\": \"Al Pacino\",\n",
    "        \"Star3\": \"James Caan\",\n",
    "        \"Star4\": \"Diane Keaton\",\n",
    "        \"No_of_Votes\": 1620367,\n",
    "        \"Gross\": \"134966411\"\n",
    "    }\n",
    "\n",
    "    df_test = pd.DataFrame([shawshank, godfather])\n",
    "    df_test_clean = basic_clean(df_test)\n",
    "\n",
    "    if df_test_clean.shape[0] > 0:\n",
    "        training_cols = df_clean.drop(columns=[\"IMDB_Rating\"]).columns\n",
    "        missing_cols = [col for col in training_cols if col not in df_test_clean.columns]\n",
    "        if missing_cols:\n",
    "            df_test_clean = pd.concat([df_test_clean, pd.DataFrame(0, index=df_test_clean.index, columns=missing_cols)], axis=1)\n",
    "        df_test_clean = df_test_clean[training_cols].astype(np.float32)\n",
    "\n",
    "        pred_rf = rf.predict(df_test_clean)[0]\n",
    "        pred_xgb = xgb.predict(df_test_clean)[0]\n",
    "        pred_xgb_best = xgb_best.predict(df_test_clean)[0]\n",
    "\n",
    "        print(f\"\\nüéØ RESULTADOS:\")\n",
    "        print(f\"üå≤ RandomForest: {pred_rf:.2f}\")\n",
    "        print(f\"‚ö° XGBoost: {pred_xgb:.2f}\")\n",
    "        print(f\"‚ö° XGBoost (Optuna): {pred_xgb_best:.2f}\")\n",
    "        print(f\"üìä Rating Real: 9.30\")\n",
    "        print(f\"üéØ Erro RF: {abs(pred_rf - 9.3):.2f}\")\n",
    "        print(f\"üéØ Erro XGB: {abs(pred_xgb - 9.3):.2f}\")\n",
    "        print(f\"üéØ Erro XGB Optuna: {abs(pred_xgb_best - 9.3):.2f}\")\n",
    "    else:\n",
    "        print(\"‚ùå Erro no processamento do exemplo\")\n",
    "\n",
    "    return df_clean, rf, xgb, xgb_best\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_models(\"data/raw/desafio_indicium_imdb.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
